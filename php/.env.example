# === Embedding Service ===
# Required. URL to the embedding API.
# Use one of the following depending on your PHP interpreter context:
# - Inside Docker container:           http://ollama:11434
# - Local PHP interpreter:             http://localhost:11434
# - PHP inside Docker, host service:   http://host.docker.internal:11434
EMBEDDING_API="http://ollama:11434"

# Required. Name of the embedding model to use.
# 'nomic-embed-text' is a balanced default.
EMBEDDING_MODEL="nomic-embed-text"

# === ChromaDB Configuration ===
# Required. URL to the ChromaDB API.
# Use one of the following depending on your PHP interpreter context:
# - Inside Docker container:           http://chromadb:8000
# - Local PHP interpreter:             http://localhost:8000
# - PHP inside Docker, host service:   http://host.docker.internal:8000
CHROMA_DB_API="http://chromadb:8000"

# === LLM Configuration ===
# Required for AI-driven features.
# Use one of the following depending on your PHP interpreter context:
# - Inside Docker container:           http://ollama:11434
# - Local PHP interpreter:             http://localhost:11434
# - PHP inside Docker, host service:   http://host.docker.internal:11434
OLLAMA_API="http://ollama:11434"

# Required for AI mode. Set the name of the LLM model to use.
# 'qwen2.5-coder:7b-base-q5_K_M' is suitable for local usage, smart and fast enough.
OLLAMA_MODEL="qwen2.5-coder:7b-base-q5_K_M"

# === Project Information ===
# Required. Absolute path to your project root directory.
# Used for displaying full clickable paths in the CLI.
PROJECT_ABSOLUTE_PATH="/Users/username/spryker/spryker-project"

# Required. Project name identifier.
PROJECT_NAME="spryker-project"

# Required. Comma separated Paths to the 'src' folder at the project level.
# PROJECT_SRC_DIRS="src/Pyz,src/CustomNamespace"
PROJECT_SRC_DIRS="src/Pyz"

# Optional.
# Use one of the following :
# - "ollama" - the default one, pull and configure OLLAMA_MODEL before usage
# Comming soon: "gemini", "anthropic", "open-ai", "deepseek", "mistral"
AI_PROVIDER="ollama"

# === Query & Display Settings ===
# Required. Maximum number of results returned for a single query.
MAX_QUERY_RESULTS=50

# Required. Maximum number of text chunks displayed per result.
MAX_CHUNK_DISPLAY_RESULTS=3
